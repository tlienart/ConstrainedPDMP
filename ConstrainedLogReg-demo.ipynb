{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression with constrained parameters\n",
    "\n",
    "In this notebook, we show how to use the package `PDMP.jl` with a logistic regression problem where the weights are constrained to the positive domain.\n",
    "This example supports the paper *Piecewise Deterministic Markov Processes for Scalable Monte Carlo on Restricted Domains* by Bierkens et al.\n",
    "Later (see section B) in the notebook, we show how the results from the paper can be reproduced.\n",
    "\n",
    "## Part1: demo on how to use the PDMP package\n",
    "\n",
    "The description below corresponds to the description of the model in the paper.\n",
    "\n",
    "The data $y_i\\in \\{-1,1\\}$ is modelled by\n",
    "\n",
    "$$ p(y_i | \\xi_i, \\beta) = f(y_i\\beta^T \\xi_i)$$\n",
    "\n",
    "where $\\xi\\in\\mathbb R^{n\\times p}$ are fixed covariates and \n",
    "\n",
    "$$f(z)=(1+\\exp(-z))^{-1}\\in[0,1].$$ \n",
    "\n",
    "The parameter $\\beta$ is constrained to be in the positive orthant ($\\beta_i\\ge 0$).\n",
    "\n",
    "In the experiments, the dimensions are set to $n=10000$ and $p=20$. The entries of $\\xi$ and the generating $\\beta$ are drawn iid from a uniform on $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PDMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring the model\n",
    "\n",
    "#### Basics\n",
    "\n",
    "In the next cell, we seed the random number generator for reproducibility and define the elements of the model.\n",
    "\n",
    "Note that:\n",
    "\n",
    "* the package PDMP implements the logistic function which is used to generate labels.\n",
    "* we define a proxy for the \"$NL$ upper bound\", this corresponds to the paper, equation A4 (use of thinning method with a linear upper bound for the logistic regression):\n",
    "\n",
    "$$ \\left\\langle \\nabla U(\\hat x) + N(\\nabla U^i(X_t) - \\nabla U^i(\\hat x)), v\\right\\rangle^+  \\le \\langle\\nabla U(\\hat x), v\\rangle^+ + NL\\|x-\\hat x\\| + NL t$$\n",
    "\n",
    "where $z^+=\\max\\{0,z\\}$. The paper shows that for the logistic regression, the equation holds with\n",
    "\n",
    "$$ L := {1\\over 4}\\max_i \\|\\xi_i\\| $$ \n",
    "\n",
    "* the data model defined last is an object that encapsulates how the log-likelihood and derived quantities such as the gradient are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srand(1777)\n",
    "\n",
    "n, p = 10000, 20\n",
    "\n",
    "ξ = rand(n, p)  # feature matrix\n",
    "β = rand(p)     # ground truth \n",
    "\n",
    "# Generate labels on {-1,+1}\n",
    "y = (PDMP.logistic.(ξ * β) .> rand(n))\n",
    "y = y * 2 - 1\n",
    "\n",
    "# proxy for the N*L upper bound\n",
    "b = sum( mapslices(ξi->norm(ξi)^2, ξ, 1) )/4\n",
    "\n",
    "# Declare the Data Model\n",
    "dm = PDMP.LogReg(ξ, y, b)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geometry\n",
    "\n",
    "We can now define the geometry associated with the model. In particular we want to be able to compute when a particular ray will hit a boundary and which boundary. A ray is understood to be the linear trajectory starting at $x$ and following $x+tv$ for $t>0$.\n",
    "\n",
    "Here, the domain is simply defined by the non-negativity constraints. Since it is a polygonal domain, we just need to specify the normals to the faces (`ns`) and their intercepts (`a`). In the case of the positive orthant the normals are simply the canonical basis and intercepts are `0`. \n",
    "\n",
    "Once the geometry is defined, the `nextboundary` method allows to define the function which, for a given ray, indicates what is the next boundary that will be hit and when."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the geometry\n",
    "ns, a = eye(p), zeros(p)\n",
    "geom  = PDMP.Polygonal(ns, a)\n",
    "\n",
    "# The geometry defines the 'nextboundary' along a ray\n",
    "nextboundary(x, v) = PDMP.nextboundary(geom, x, v)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Events along a ray\n",
    "\n",
    "Now we need to specify how to handle the Inhomogenous Poisson Process (IPP) associated with the problem. In this case, as detailed in the paper, we consider thinning with a linear upper bound. \n",
    "\n",
    "The linear upper bound can be defined via the package using `PDMP.LinearBound`. The method `nextevent_bps` then corresponds to the sampling of the IPP along a ray using the given method.\n",
    "\n",
    "**Note**: other kernels can be used here (e.g.: zig-zag), please refer to the package documentation for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients and sampling of IPP\n",
    "gll_cv       = PDMP.gradloglik_cv(dm, β)\n",
    "gll_star     = PDMP.gradloglik(dm, β)\n",
    "linear_bound = PDMP.LinearBound(β, gll_star, dm.b)\n",
    "\n",
    "# define how to compute the next event along a ray\n",
    "nextevent(x, v) = PDMP.nextevent_bps(linear_bound, x, v)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the simulation\n",
    "\n",
    "We now need to define the simulation parameters:\n",
    "\n",
    "Stopping criterions:\n",
    "* if event times are larger than `T`, here we set it to `Inf` as we don't want it to be the stopping criterion but rather want to set a number of gradient evaluations.\n",
    "* if the number of gradient evaluation is larger than `maxgradeval`\n",
    "\n",
    "Other parameters:\n",
    "\n",
    "* $\\lambda_{\\text{ref}}$ is the refreshment rate (see documentation of `PDMP.jl`)\n",
    "* $x_0, v_0$ are the initial starting points and velocity\n",
    "* `sim` encapsulates all the parameters\n",
    "\n",
    "Then, the only thing left to do is to run the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T           = Inf      \n",
    "maxgradeval = 1000*1000 # these are CV gradients so very cheap\n",
    "λ_ref       = 2.\n",
    "\n",
    "x0  = rand(dm.p)\n",
    "v0  = randn(dm.p)\n",
    "v0 /= norm(v0)\n",
    "\n",
    "sim = PDMP.Simulation(x0, v0, T, nextevent,\n",
    "                      gll_cv, nextboundary, λ_ref;\n",
    "                      maxgradeval = maxgradeval)\n",
    "\n",
    "(path, details) = PDMP.simulate(sim)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having a look at the results\n",
    "\n",
    "#### Simulation details\n",
    "\n",
    "The `details` dictionary contains informations about the simulation such as the number of boundary hits (`nboundary`), the clocktime, the number of refreshments etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 7 entries:\n",
       "  \"nboundary\" => 315\n",
       "  \"nsegments\" => 1103\n",
       "  \"clocktime\" => 37.1363\n",
       "  \"nloops\"    => 1000370\n",
       "  \"nbounce\"   => 732\n",
       "  \"ngradeval\" => 1000000\n",
       "  \"nrefresh\"  => 55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path object\n",
    "\n",
    "The `path` object corresponds to the path generated with the simulation. You could for example:\n",
    "\n",
    "* sample it using the `samplepath` function\n",
    "* obtain the mean for each dimension via the `pathmean` function\n",
    "* obtain the ess for each dimension via the `esspath` function\n",
    "\n",
    "(refer to `PDMP.jl` for more informations)\n",
    "\n",
    "**Note**: when using Julia 0.6, using `esspath` may show a warning, this is because it relies on the package `Klara.jl` which uses deprecated syntax. You can safely ignore that warning. If you'd like to not see such warnings, run this:\n",
    "\n",
    "```julia\n",
    "using IJulia\n",
    "IJulia.installkernel(\"Julia nodeps\", \"--depwarn=no\")\n",
    "```\n",
    "\n",
    "then restart the notebook and change the kernel to Julia nodeps (see also `README.md`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.153\n",
      "Min ESS: 9.5\n",
      "Max ESS: 55.8\n"
     ]
    }
   ],
   "source": [
    "# Compute the RMSE\n",
    "ypred = PDMP.logistic.(ξ * PDMP.pathmean(path)) * 2 - 1\n",
    "rmse  = sqrt(sum((ypred-y).^2)/length(y))\n",
    "println(\"RMSE: $(round(rmse,3))\")\n",
    "\n",
    "# Show the average ESS across dimensions\n",
    "all_ess = PDMP.esspath(path)[1]\n",
    "println(\"Min ESS: $(round(minimum(all_ess),1))\")\n",
    "println(\"Max ESS: $(round(maximum(all_ess),1))\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia nodeps 0.6.0",
   "language": "julia",
   "name": "julia-nodeps-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
